{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Install Dependencies"
      ],
      "metadata": {
        "id": "B-Qcy-BoCFMl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch torchaudio numpy transformers librosa"
      ],
      "metadata": {
        "id": "D0_1ApxOB8B5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Connecting Google Drive"
      ],
      "metadata": {
        "id": "YVubsAHMVdfU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Xj3B3rXYVYPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing Libraries"
      ],
      "metadata": {
        "id": "KXaoDkAaCJMl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from transformers import Wav2Vec2Model, HubertModel, WavLMModel\n",
        "import numpy as np\n",
        "from sklearn.metrics import roc_curve\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchaudio\n",
        "import os\n",
        "import tarfile\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "vm04TmIVBZY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading Data"
      ],
      "metadata": {
        "id": "MFV_rbRyVo3d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Paths\n",
        "protocol_path = '/content/drive/MyDrive/ASVspoof5_protocols/ASVspoof5.train.tsv'\n",
        "audio_dir = '/content/drive/MyDrive/flac_T_aa'"
      ],
      "metadata": {
        "id": "MYuSdJFJYzgB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Custom Dataset\n",
        "class ASVspoofDataset(Dataset):\n",
        "    def __init__(self, audio_dir, label_map, transform=None):\n",
        "        self.audio_dir = audio_dir\n",
        "        self.label_map = label_map\n",
        "        self.files = list(label_map.keys())\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        filename = self.files[idx]\n",
        "        filepath = os.path.join(self.audio_dir, filename)\n",
        "        waveform, sample_rate = torchaudio.load(filepath)\n",
        "\n",
        "        # Optional: Add transformations (e.g., MFCC, MelSpectrogram)\n",
        "        if self.transform:\n",
        "            waveform = self.transform(waveform)\n",
        "\n",
        "        label = self.label_map[filename]\n",
        "        return waveform, label\n"
      ],
      "metadata": {
        "id": "gG2e9uOpV_Cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Parse the protocol file and filter available files\n",
        "def parse_and_filter_protocol(protocol_path, audio_dir):\n",
        "    label_map = {}\n",
        "    available_files = set(os.listdir(audio_dir))\n",
        "\n",
        "    with open(protocol_path, 'r') as file:\n",
        "        for line in file:\n",
        "            parts = line.strip().split('\\t')\n",
        "            utt_id, label = parts[0], parts[2]\n",
        "            audio_file = utt_id + '.flac'\n",
        "            if audio_file in available_files:\n",
        "                label_map[audio_file] = 0 if label == 'bonafide' else 1\n",
        "    return label_map\n",
        "\n"
      ],
      "metadata": {
        "id": "HID5-wCtWXXn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load label map and split into train/test\n",
        "label_map = parse_and_filter_protocol(protocol_path, audio_dir)\n",
        "\n",
        "train_keys, test_keys = train_test_split(list(label_map.keys()), test_size=0.2, random_state=42)\n",
        "train_map = {k: label_map[k] for k in train_keys}\n",
        "test_map = {k: label_map[k] for k in test_keys}\n"
      ],
      "metadata": {
        "id": "JFZksCqbWoMZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Datasets and DataLoaders\n",
        "train_dataset = ASVspoofDataset(audio_dir, train_map)\n",
        "test_dataset = ASVspoofDataset(audio_dir, test_map)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n"
      ],
      "metadata": {
        "id": "hORmi8C5ZAuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Traning Architecture"
      ],
      "metadata": {
        "id": "DeW39aKUCNUx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Residual Block ---\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, num_layers=2):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.SELU(),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.SELU(),\n",
        "        )\n",
        "\n",
        "        # Ensure residual connection has the same dimensions\n",
        "        self.residual = nn.Conv2d(in_channels, out_channels, kernel_size=1) if in_channels != out_channels else nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x) + self.residual(x)\n",
        "\n",
        "\n",
        "# --- Forgery Detection Model ---\n",
        "class ForgeryDetectionModel(nn.Module):\n",
        "    def __init__(self, ssl_model_name):\n",
        "        super(ForgeryDetectionModel, self).__init__()\n",
        "\n",
        "        # Load SSL model dynamically\n",
        "        self.ssl_model = get_ssl_model(ssl_model_name)\n",
        "        self.ssl_out_dim = self.ssl_model.config.hidden_size  # Typically 768\n",
        "\n",
        "        # Dimensionality Reduction\n",
        "        self.fc1 = nn.Linear(self.ssl_out_dim, 128)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=3, stride=3)\n",
        "        self.bn_selu = nn.Sequential(\n",
        "            nn.BatchNorm2d(1),\n",
        "            nn.SELU()\n",
        "        )\n",
        "\n",
        "        # Residual Blocks\n",
        "        self.res_block1 = ResidualBlock(1, 32, num_layers=2)\n",
        "        self.res_block2 = ResidualBlock(32, 64, num_layers=4)\n",
        "\n",
        "        # Global Average Pooling & Classification\n",
        "        self.global_avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc2 = nn.Linear(64, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # SSL frontend\n",
        "        x = self.ssl_model(x).last_hidden_state  # (B, T, 768)\n",
        "\n",
        "        # Dimensionality Reduction\n",
        "        x = self.fc1(x)  # (B, T, 128)\n",
        "        x = x.unsqueeze(1)  # Add channel dimension for CNN (B, 1, T, 128)\n",
        "        x = self.pool(x)  # (B, 1, 67, 42)\n",
        "        x = self.bn_selu(x)  # Apply BN & SeLU\n",
        "\n",
        "        # Residual Blocks\n",
        "        x = self.res_block1(x)  # (B, 32, 67, 42)\n",
        "        x = self.res_block2(x)  # (B, 64, 67, 42)\n",
        "\n",
        "        # Global Average Pooling & Classification\n",
        "        x = self.global_avg_pool(x)  # (B, 64, 1, 1)\n",
        "        x = x.view(x.size(0), -1)  # Flatten (B, 64)\n",
        "        x = self.fc2(x)  # (B, 2)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "tOK9-ODYBa8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation Implementation"
      ],
      "metadata": {
        "id": "TrSYJFJtCSFc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Function to Compute EER ---\n",
        "def compute_eer(y_true, y_scores):\n",
        "    fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
        "    fnr = 1 - tpr\n",
        "    eer_threshold = thresholds[np.nanargmin(np.abs(fnr - fpr))]\n",
        "    eer = fpr[np.nanargmin(np.abs(fnr - fpr))]\n",
        "    return eer * 100, eer_threshold\n",
        "\n",
        "# --- Function to Compute t-DCF ---\n",
        "def compute_tdcf(y_true, y_scores, P_miss=1, P_fa=1):\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
        "    fnr = 1 - tpr\n",
        "    tdcf = P_miss * fnr + P_fa * fpr\n",
        "    return min(tdcf)"
      ],
      "metadata": {
        "id": "ndrewVjqBefP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Traning and Evaluation"
      ],
      "metadata": {
        "id": "1qLXnBLgCWHL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XNws3jIIAUlh"
      },
      "outputs": [],
      "source": [
        "# --- Function to Select SSL Model ---\n",
        "def get_ssl_model(model_name):\n",
        "    if \"wav2vec2\" in model_name:\n",
        "        return Wav2Vec2Model.from_pretrained(model_name)\n",
        "    elif \"hubert\" in model_name:\n",
        "        return HubertModel.from_pretrained(model_name)\n",
        "    elif \"wavlm\" in model_name:\n",
        "        return WavLMModel.from_pretrained(model_name)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown SSL Model: {model_name}\")\n",
        "\n",
        "\n",
        "# --- Evaluate Model ---\n",
        "def evaluate_model(model, test_loader, device):\n",
        "    model.eval()\n",
        "    y_true, y_scores = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            audio, labels = batch\n",
        "            audio = audio.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            logits = model(audio)\n",
        "            probs = F.softmax(logits, dim=1)[:, 1].cpu().numpy()\n",
        "            y_scores.extend(probs)\n",
        "            y_true.extend(labels.cpu().numpy())\n",
        "\n",
        "    eer, eer_threshold = compute_eer(y_true, y_scores)\n",
        "    tdcf = compute_tdcf(y_true, y_scores)\n",
        "\n",
        "    print(f\"EER: {eer:.2f}%\")\n",
        "    print(f\"t-DCF: {tdcf:.4f}\")\n",
        "\n",
        "    return eer, tdcf\n",
        "\n",
        "# --- Train Model ---\n",
        "def train_model(model, train_loader, device, optimizer, criterion, num_epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_loss = 0\n",
        "        correct_preds = 0\n",
        "        total_preds = 0\n",
        "\n",
        "        for batch in train_loader:\n",
        "            audio, labels = batch\n",
        "            audio = audio.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            logits = model(audio)\n",
        "            loss = criterion(logits, labels)\n",
        "\n",
        "            # Backward pass\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "            # Metrics for classification accuracy\n",
        "            _, predicted = torch.max(logits, 1)\n",
        "            correct_preds += (predicted == labels).sum().item()\n",
        "            total_preds += labels.size(0)\n",
        "\n",
        "        epoch_accuracy = 100 * correct_preds / total_preds\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Run Model for Different SSL Frontends ---\n",
        "ssl_models = [\"facebook/wav2vec2-base\", \"facebook/hubert-base-ls960\", \"microsoft/wavlm-base-plus\"]\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "for ssl_model in ssl_models:\n",
        "    print(f\"\\nTraining and Evaluating Model with {ssl_model}...\")\n",
        "\n",
        "    model = ForgeryDetectionModel(ssl_model).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-6)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    train_model(model, train_loader, device, optimizer, criterion, num_epochs=10)\n",
        "    evaluate_model(model, test_loader, device)"
      ],
      "metadata": {
        "id": "WomdWhgAXomA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}